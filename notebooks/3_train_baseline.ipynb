{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","gpuType":"V6E1","authorship_tag":"ABX9TyMU/rdoQx9eb3dqzzO2n+iA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N5HSfObvwdtl","executionInfo":{"status":"ok","timestamp":1771405068448,"user_tz":-180,"elapsed":6080,"user":{"displayName":"Ильдар Тазиев","userId":"03868066195765638499"}},"outputId":"83a079d9-9cb7-4bd3-d6d6-aa2c8ee8e6b5","collapsed":true},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n","Requirement already satisfied: polars in /usr/local/lib/python3.12/dist-packages (1.38.1)\n","Requirement already satisfied: polars-runtime-32==1.38.1 in /usr/local/lib/python3.12/dist-packages (from polars) (1.38.1)\n","Collecting Dask\n","  Using cached dask-2026.1.2-py3-none-any.whl.metadata (3.8 kB)\n","Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.12/dist-packages (from Dask) (8.3.1)\n","Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from Dask) (3.1.2)\n","Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.12/dist-packages (from Dask) (2025.10.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from Dask) (26.0)\n","Collecting partd>=1.4.0 (from Dask)\n","  Using cached partd-1.4.2-py3-none-any.whl.metadata (4.6 kB)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from Dask) (6.0.3)\n","Requirement already satisfied: toolz>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from Dask) (1.1.0)\n","Collecting locket (from partd>=1.4.0->Dask)\n","  Downloading locket-1.0.0-py2.py3-none-any.whl.metadata (2.8 kB)\n","Downloading dask-2026.1.2-py3-none-any.whl (1.5 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading partd-1.4.2-py3-none-any.whl (18 kB)\n","Downloading locket-1.0.0-py2.py3-none-any.whl (4.4 kB)\n","Installing collected packages: locket, partd, Dask\n","Successfully installed Dask-2026.1.2 locket-1.0.0 partd-1.4.2\n"]}],"source":["# @title Подключение к диску с данными\n","import os\n","from google.colab import drive\n","drive.mount('/content/drive')\n","!pip install polars\n","!pip install Dask"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oF_orkmnvxJL","outputId":"665aa0dd-22fc-40fa-b4fd-81bb12fd960d"},"outputs":[{"output_type":"stream","name":"stdout","text":["  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","  \n","  \u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n","  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","  \u001b[31m╰─>\u001b[0m See above for output.\n","  \n","  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25herror\n","\u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n","\n","\u001b[31m×\u001b[0m \u001b[32mGetting requirements to build wheel\u001b[0m did not run successfully.\n","\u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n","\u001b[31m╰─>\u001b[0m See above for output.\n","\n","\u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n","Requirement already satisfied: dask[distributed] in /usr/local/lib/python3.12/dist-packages (2026.1.2)\n","Requirement already satisfied: click>=8.1 in /usr/local/lib/python3.12/dist-packages (from dask[distributed]) (8.3.1)\n","Requirement already satisfied: cloudpickle>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from dask[distributed]) (3.1.2)\n","Requirement already satisfied: fsspec>=2021.09.0 in /usr/local/lib/python3.12/dist-packages (from dask[distributed]) (2025.10.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from dask[distributed]) (26.0)\n","Requirement already satisfied: partd>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from dask[distributed]) (1.4.2)\n","Requirement already satisfied: pyyaml>=5.3.1 in /usr/local/lib/python3.12/dist-packages (from dask[distributed]) (6.0.3)\n","Requirement already satisfied: toolz>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from dask[distributed]) (1.1.0)\n","Requirement already satisfied: distributed<2026.1.3,>=2026.1.2 in /usr/local/lib/python3.12/dist-packages (from dask[distributed]) (2026.1.2)\n","Requirement already satisfied: jinja2>=2.10.3 in /usr/local/lib/python3.12/dist-packages (from distributed<2026.1.3,>=2026.1.2->dask[distributed]) (3.1.6)\n","Requirement already satisfied: locket>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from distributed<2026.1.3,>=2026.1.2->dask[distributed]) (1.0.0)\n","Requirement already satisfied: msgpack>=1.0.2 in /usr/local/lib/python3.12/dist-packages (from distributed<2026.1.3,>=2026.1.2->dask[distributed]) (1.1.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from distributed<2026.1.3,>=2026.1.2->dask[distributed]) (5.9.5)\n","Requirement already satisfied: sortedcontainers>=2.0.5 in /usr/local/lib/python3.12/dist-packages (from distributed<2026.1.3,>=2026.1.2->dask[distributed]) (2.4.0)\n","Requirement already satisfied: tblib!=3.2.0,!=3.2.1,>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from distributed<2026.1.3,>=2026.1.2->dask[distributed]) (3.2.2)\n","Requirement already satisfied: tornado>=6.2.0 in /usr/local/lib/python3.12/dist-packages (from distributed<2026.1.3,>=2026.1.2->dask[distributed]) (6.5.1)\n","Requirement already satisfied: urllib3>=1.26.5 in /usr/local/lib/python3.12/dist-packages (from distributed<2026.1.3,>=2026.1.2->dask[distributed]) (2.5.0)\n","Requirement already satisfied: zict>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from distributed<2026.1.3,>=2026.1.2->dask[distributed]) (3.0.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=2.10.3->distributed<2026.1.3,>=2026.1.2->dask[distributed]) (3.0.3)\n","Collecting lightgbm\n","  Using cached lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl.metadata (17 kB)\n","Requirement already satisfied: numpy>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from lightgbm) (2.0.2)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from lightgbm) (1.16.3)\n","Downloading lightgbm-4.6.0-py3-none-manylinux_2_28_x86_64.whl (3.6 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: lightgbm\n","Successfully installed lightgbm-4.6.0\n"]},{"output_type":"stream","name":"stderr","text":["INFO:distributed.http.proxy:To route to workers diagnostics web server please install jupyter-server-proxy: python -m pip install jupyter-server-proxy\n","INFO:distributed.scheduler:State start\n","INFO:distributed.scheduler:  Scheduler at:     tcp://127.0.0.1:38457\n","INFO:distributed.scheduler:  dashboard at:  http://127.0.0.1:8787/status\n","INFO:distributed.scheduler:Registering Worker plugin shuffle\n","INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:45975'\n"]},{"output_type":"stream","name":"stdout","text":["Начало обучения Dask-LightGBM baseline 2026-02-18 08:59\n","Запуск Dask Client...\n"]},{"output_type":"stream","name":"stderr","text":["INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:33803'\n","INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:39885'\n","INFO:distributed.nanny:        Start Nanny at: 'tcp://127.0.0.1:41883'\n","INFO:distributed.scheduler:Register worker addr: tcp://127.0.0.1:40283 name: 2\n","INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:40283\n","INFO:distributed.core:Starting established connection to tcp://127.0.0.1:60896\n","INFO:distributed.scheduler:Register worker addr: tcp://127.0.0.1:46625 name: 0\n","INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:46625\n","INFO:distributed.core:Starting established connection to tcp://127.0.0.1:60900\n","INFO:distributed.scheduler:Register worker addr: tcp://127.0.0.1:37503 name: 1\n","INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:37503\n","INFO:distributed.core:Starting established connection to tcp://127.0.0.1:60916\n","INFO:distributed.scheduler:Register worker addr: tcp://127.0.0.1:34827 name: 3\n","INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:34827\n","INFO:distributed.core:Starting established connection to tcp://127.0.0.1:60932\n","INFO:distributed.scheduler:Receive client connection: Client-281fe844-0ca8-11f1-85b3-0242ac1c000c\n","INFO:distributed.core:Starting established connection to tcp://127.0.0.1:60940\n"]},{"output_type":"stream","name":"stdout","text":["http://127.0.0.1:8787/status\n","Считываем метаданные для разбиения...\n","Train parts: 2 | Valid: 1\n","Количество признаков: 39\n"]},{"output_type":"stream","name":"stderr","text":["WARNING:distributed.nanny.memory:Worker tcp://127.0.0.1:34827 (pid=3119) exceeded 95% memory budget. Restarting...\n","INFO:distributed.core:Connection to tcp://127.0.0.1:60932 has been closed.\n","INFO:distributed.scheduler:Remove worker addr: tcp://127.0.0.1:34827 name: 3 (stimulus_id='handle-worker-cleanup-1771405227.5911317')\n","WARNING:distributed.scheduler:Removing worker 'tcp://127.0.0.1:34827' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('astype-fb818f6250987c042cbc7345ea103644', 4), ('astype-e2d75f2d023a6c1db31cdde7fee98e61', 19), ('read_parquet-fused-126ea040e73af77d6567f1d493927c48', 19), ('astype-87bf3f49e98303d1203cb1db10400a2a', 4), ('astype-c6feec26192e1c3559ececb2b5fa99af', 4), ('astype-8c14a25ca9323af795e3dc15fb8f7e86', 4), ('astype-e9b5734a4b3b89191f9744c2f8c4d2a2', 4), ('astype-e1e5ab3f2699553e4a45b625569862f9', 4), ('astype-9147447c131181f75ccdc778a49a14d8', 4), ('astype-1720b31f3e8d2bad5acdd553f299863c', 4), ('astype-5007e0e1f04f865259be95d727f83cb5', 4), ('getitem-4eb206f50500a7c0d431e1d6b3209777', 4), ('astype-43f9c3943b490790d82a2cda171af016', 4), ('astype-e2d75f2d023a6c1db31cdde7fee98e61', 4), ('getitem-4eb206f50500a7c0d431e1d6b3209777', 19), ('astype-b6b6f1bca8d8c87b539d7382f39cdc6d', 4)} (stimulus_id='handle-worker-cleanup-1771405227.5911317')\n","INFO:distributed.nanny:Worker process 3119 was killed by signal 15\n","WARNING:distributed.nanny:Restarting worker\n","INFO:distributed.scheduler:Register worker addr: tcp://127.0.0.1:36633 name: 3\n","INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:36633\n","INFO:distributed.core:Starting established connection to tcp://127.0.0.1:43072\n","WARNING:distributed.nanny.memory:Worker tcp://127.0.0.1:37503 (pid=3113) exceeded 95% memory budget. Restarting...\n","INFO:distributed.core:Connection to tcp://127.0.0.1:60916 has been closed.\n","INFO:distributed.scheduler:Remove worker addr: tcp://127.0.0.1:37503 name: 1 (stimulus_id='handle-worker-cleanup-1771405291.3847587')\n","WARNING:distributed.scheduler:Removing worker 'tcp://127.0.0.1:37503' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('read_parquet-fused-126ea040e73af77d6567f1d493927c48', 10), ('astype-e1e5ab3f2699553e4a45b625569862f9', 8), ('astype-1720b31f3e8d2bad5acdd553f299863c', 8), ('astype-8c14a25ca9323af795e3dc15fb8f7e86', 8), ('astype-87bf3f49e98303d1203cb1db10400a2a', 10), ('astype-5007e0e1f04f865259be95d727f83cb5', 8), ('getitem-4eb206f50500a7c0d431e1d6b3209777', 8), ('astype-9147447c131181f75ccdc778a49a14d8', 8), ('astype-43f9c3943b490790d82a2cda171af016', 8), ('astype-e9b5734a4b3b89191f9744c2f8c4d2a2', 8), ('len-190c9110b5407ac0e43260832c9a6efa', 16), ('astype-b6b6f1bca8d8c87b539d7382f39cdc6d', 8), ('astype-e2d75f2d023a6c1db31cdde7fee98e61', 8), ('astype-fb818f6250987c042cbc7345ea103644', 8), ('getitem-90fc7f3aacf75b79032b25e579503ee1', 10), ('astype-c6feec26192e1c3559ececb2b5fa99af', 8), ('astype-87bf3f49e98303d1203cb1db10400a2a', 8)} (stimulus_id='handle-worker-cleanup-1771405291.3847587')\n","INFO:distributed.nanny:Worker process 3113 was killed by signal 15\n","WARNING:distributed.nanny:Restarting worker\n","WARNING:distributed.nanny.memory:Worker tcp://127.0.0.1:46625 (pid=3109) exceeded 95% memory budget. Restarting...\n","INFO:distributed.scheduler:Register worker addr: tcp://127.0.0.1:35385 name: 1\n","INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:35385\n","INFO:distributed.core:Starting established connection to tcp://127.0.0.1:44638\n","INFO:distributed.core:Connection to tcp://127.0.0.1:60900 has been closed.\n","INFO:distributed.scheduler:Remove worker addr: tcp://127.0.0.1:46625 name: 0 (stimulus_id='handle-worker-cleanup-1771405291.796346')\n","WARNING:distributed.scheduler:Removing worker 'tcp://127.0.0.1:46625' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('getitem-4eb206f50500a7c0d431e1d6b3209777', 6), ('astype-43f9c3943b490790d82a2cda171af016', 6), ('astype-9147447c131181f75ccdc778a49a14d8', 6), ('astype-e9b5734a4b3b89191f9744c2f8c4d2a2', 6), ('astype-b6b6f1bca8d8c87b539d7382f39cdc6d', 6), ('astype-e2d75f2d023a6c1db31cdde7fee98e61', 6), ('astype-fb818f6250987c042cbc7345ea103644', 6), ('astype-8c14a25ca9323af795e3dc15fb8f7e86', 6), ('assign-f9f7c99edbc5158b6174567b71268950', 13), ('astype-9147447c131181f75ccdc778a49a14d8', 1), ('astype-87bf3f49e98303d1203cb1db10400a2a', 6), ('astype-c6feec26192e1c3559ececb2b5fa99af', 6), ('astype-e1e5ab3f2699553e4a45b625569862f9', 6), ('astype-1720b31f3e8d2bad5acdd553f299863c', 6), ('read_parquet-fused-126ea040e73af77d6567f1d493927c48', 1), ('astype-5007e0e1f04f865259be95d727f83cb5', 6)} (stimulus_id='handle-worker-cleanup-1771405291.796346')\n","INFO:distributed.nanny:Worker process 3109 was killed by signal 15\n","WARNING:distributed.nanny:Restarting worker\n","INFO:distributed.scheduler:Register worker addr: tcp://127.0.0.1:37461 name: 0\n","INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:37461\n","INFO:distributed.core:Starting established connection to tcp://127.0.0.1:47626\n","WARNING:distributed.nanny.memory:Worker tcp://127.0.0.1:35385 (pid=3637) exceeded 95% memory budget. Restarting...\n","INFO:distributed.core:Connection to tcp://127.0.0.1:44638 has been closed.\n","INFO:distributed.scheduler:Remove worker addr: tcp://127.0.0.1:35385 name: 1 (stimulus_id='handle-worker-cleanup-1771405312.1537988')\n","WARNING:distributed.scheduler:Removing worker 'tcp://127.0.0.1:35385' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('read_parquet-fused-126ea040e73af77d6567f1d493927c48', 8)} (stimulus_id='handle-worker-cleanup-1771405312.1537988')\n","INFO:distributed.nanny:Worker process 3637 was killed by signal 15\n","WARNING:distributed.nanny:Restarting worker\n","INFO:distributed.scheduler:Register worker addr: tcp://127.0.0.1:41419 name: 1\n","INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:41419\n","INFO:distributed.core:Starting established connection to tcp://127.0.0.1:36096\n","WARNING:distributed.nanny.memory:Worker tcp://127.0.0.1:40283 (pid=3117) exceeded 95% memory budget. Restarting...\n","INFO:distributed.core:Connection to tcp://127.0.0.1:60896 has been closed.\n","INFO:distributed.scheduler:Remove worker addr: tcp://127.0.0.1:40283 name: 2 (stimulus_id='handle-worker-cleanup-1771405353.0037444')\n","WARNING:distributed.scheduler:Removing worker 'tcp://127.0.0.1:40283' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('astype-8c14a25ca9323af795e3dc15fb8f7e86', 21), ('read_parquet-fused-126ea040e73af77d6567f1d493927c48', 20), ('astype-fb818f6250987c042cbc7345ea103644', 20), ('astype-e1e5ab3f2699553e4a45b625569862f9', 21), ('getitem-4eb206f50500a7c0d431e1d6b3209777', 21), ('astype-87bf3f49e98303d1203cb1db10400a2a', 20), ('astype-9147447c131181f75ccdc778a49a14d8', 21), ('astype-c6feec26192e1c3559ececb2b5fa99af', 20), ('astype-e2d75f2d023a6c1db31cdde7fee98e61', 3), ('astype-e1e5ab3f2699553e4a45b625569862f9', 20), ('len-190c9110b5407ac0e43260832c9a6efa', 7), ('read_parquet-fused-126ea040e73af77d6567f1d493927c48', 2), ('astype-c6feec26192e1c3559ececb2b5fa99af', 21), ('getitem-4eb206f50500a7c0d431e1d6b3209777', 20), ('astype-b6b6f1bca8d8c87b539d7382f39cdc6d', 21), ('astype-1720b31f3e8d2bad5acdd553f299863c', 3), ('astype-87bf3f49e98303d1203cb1db10400a2a', 21), ('len-190c9110b5407ac0e43260832c9a6efa', 5)} (stimulus_id='handle-worker-cleanup-1771405353.0037444')\n","INFO:distributed.nanny:Worker process 3117 was killed by signal 15\n","WARNING:distributed.nanny:Restarting worker\n","INFO:distributed.scheduler:Register worker addr: tcp://127.0.0.1:39501 name: 2\n","INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:39501\n","INFO:distributed.core:Starting established connection to tcp://127.0.0.1:42028\n","WARNING:distributed.nanny.memory:Worker tcp://127.0.0.1:37461 (pid=3647) exceeded 95% memory budget. Restarting...\n","INFO:distributed.core:Connection to tcp://127.0.0.1:47626 has been closed.\n","INFO:distributed.scheduler:Remove worker addr: tcp://127.0.0.1:37461 name: 0 (stimulus_id='handle-worker-cleanup-1771405356.8012795')\n","WARNING:distributed.scheduler:Removing worker 'tcp://127.0.0.1:37461' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('getitem-39b3e952fb7d2f3c97666dcc41361d60', 4), ('getitem-8aa37ccffa0ab0f811f94ee2cf2f7461', 4), ('getitem-8ef5e2fe59524e69936ec74c4019e2da', 4), ('read_parquet-fused-126ea040e73af77d6567f1d493927c48', 24), ('assign-f9f7c99edbc5158b6174567b71268950', 6)} (stimulus_id='handle-worker-cleanup-1771405356.8012795')\n","INFO:distributed.nanny:Worker process 3647 was killed by signal 15\n","WARNING:distributed.nanny:Restarting worker\n","WARNING:distributed.nanny.memory:Worker tcp://127.0.0.1:36633 (pid=3366) exceeded 95% memory budget. Restarting...\n","INFO:distributed.core:Connection to tcp://127.0.0.1:43072 has been closed.\n","INFO:distributed.scheduler:Remove worker addr: tcp://127.0.0.1:36633 name: 3 (stimulus_id='handle-worker-cleanup-1771405357.1564493')\n","WARNING:distributed.scheduler:Removing worker 'tcp://127.0.0.1:36633' caused the cluster to lose already computed task(s), which will be recomputed elsewhere: {('astype-b6b6f1bca8d8c87b539d7382f39cdc6d', 23), ('astype-1720b31f3e8d2bad5acdd553f299863c', 21), ('astype-e1e5ab3f2699553e4a45b625569862f9', 23), ('astype-e9b5734a4b3b89191f9744c2f8c4d2a2', 21), ('astype-fb818f6250987c042cbc7345ea103644', 21), ('getitem-4eb206f50500a7c0d431e1d6b3209777', 4), ('len-190c9110b5407ac0e43260832c9a6efa', 9), ('astype-43f9c3943b490790d82a2cda171af016', 23), ('astype-5007e0e1f04f865259be95d727f83cb5', 21), ('astype-c6feec26192e1c3559ececb2b5fa99af', 23), ('astype-87bf3f49e98303d1203cb1db10400a2a', 23), ('astype-e2d75f2d023a6c1db31cdde7fee98e61', 21), ('astype-1720b31f3e8d2bad5acdd553f299863c', 23), ('astype-43f9c3943b490790d82a2cda171af016', 4), ('astype-e9b5734a4b3b89191f9744c2f8c4d2a2', 23), ('astype-fb818f6250987c042cbc7345ea103644', 23), ('read_parquet-fused-126ea040e73af77d6567f1d493927c48', 19), ('astype-87bf3f49e98303d1203cb1db10400a2a', 4), ('astype-c6feec26192e1c3559ececb2b5fa99af', 4), ('astype-8c14a25ca9323af795e3dc15fb8f7e86', 23), ('astype-1720b31f3e8d2bad5acdd553f299863c', 4), ('astype-5007e0e1f04f865259be95d727f83cb5', 23), ('astype-e9b5734a4b3b89191f9744c2f8c4d2a2', 4), ('astype-e2d75f2d023a6c1db31cdde7fee98e61', 23), ('astype-fb818f6250987c042cbc7345ea103644', 4), ('astype-8c14a25ca9323af795e3dc15fb8f7e86', 4), ('astype-43f9c3943b490790d82a2cda171af016', 21), ('astype-5007e0e1f04f865259be95d727f83cb5', 4), ('len-190c9110b5407ac0e43260832c9a6efa', 22), ('getitem-4eb206f50500a7c0d431e1d6b3209777', 23), ('astype-e2d75f2d023a6c1db31cdde7fee98e61', 4)} (stimulus_id='handle-worker-cleanup-1771405357.1564493')\n","INFO:distributed.nanny:Worker process 3366 was killed by signal 15\n","WARNING:distributed.nanny:Restarting worker\n","INFO:distributed.scheduler:Register worker addr: tcp://127.0.0.1:40353 name: 0\n","INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:40353\n","INFO:distributed.core:Starting established connection to tcp://127.0.0.1:42044\n","INFO:distributed.scheduler:Register worker addr: tcp://127.0.0.1:33135 name: 3\n","INFO:distributed.scheduler:Starting worker compute stream, tcp://127.0.0.1:33135\n","INFO:distributed.core:Starting established connection to tcp://127.0.0.1:42054\n"]}],"source":["# 3_train_baseline_dask.py\n","# @title Dask-LightGBM baseline для Data Fusion Contest 2026 \"Страж\" с обучением по частям (для OOM)\n","\n","!pip install --quiet dask[complete] lightgbm dask-ml dask-lightgbm\n","!pip install \"dask[distributed]\"\n","!pip install lightgbm\n","\n","import polars as pl\n","import dask.dataframe as dd\n","import dask.array as da\n","from dask.distributed import Client\n","import lightgbm as lgb\n","from lightgbm.dask import DaskLGBMClassifier\n","from sklearn.metrics import average_precision_score\n","import numpy as np\n","import gc\n","import os\n","from datetime import datetime\n","\n","print(\"Начало обучения Dask-LightGBM baseline\", datetime.now().strftime(\"%Y-%m-%d %H:%M\"))\n","\n","DATA_PATH = \"/content/drive/MyDrive/ml-vtb-data-fusion-strazh/data/\"\n","MODEL_PATH = \"./models/\"\n","os.makedirs(MODEL_PATH, exist_ok=True)\n","\n","# ─── Параметры Dask ───────────────────────────────────────────────────────────\n","\n","N_WORKERS = 4                  # подбери под свой CPU (i3 — 2–4)\n","THREADS_PER_WORKER = 1         # для LightGBM\n","MEMORY_LIMIT = 'auto'          # или '8GB' per worker, если нужно ограничить\n","\n","# ─── Параметры модели ─────────────────────────────────────────────────────────\n","\n","N_ESTIMATORS      = 2500\n","LEARNING_RATE     = 0.035\n","MAX_DEPTH         = 9\n","NUM_LEAVES        = 120\n","FEATURE_FRACTION  = 0.75\n","BAGGING_FRACTION  = 0.80\n","BAGGING_FREQ      = 5\n","POS_WEIGHT        = 350          # подбери по соотношению ~1 : 1500–4000\n","\n","EARLY_STOPPING    = 120\n","VERBOSE_EVAL      = 100\n","\n","# ─── Категориальные признаки ─────────────────────────────────────────────────\n","\n","cat_features = [\n","    \"event_type_nm\",\n","    \"channel_indicator_type\",\n","    \"channel_indicator_sub_type\",\n","    \"currency_iso_cd\",\n","    \"mcc_code\",\n","    \"pos_cd\",\n","    \"accept_language\",\n","    \"browser_language\",\n","    \"timezone\",\n","    \"operating_system_type\",\n","    \"device_system_version\",\n","    \"screen_size\",\n","    # если есть ещё категориальные — добавь\n","]\n","\n","# ─── Dask Client ──────────────────────────────────────────────────────────────\n","\n","print(\"Запуск Dask Client...\")\n","client = Client(\n","    n_workers=N_WORKERS,\n","    threads_per_worker=THREADS_PER_WORKER,\n","    memory_limit=MEMORY_LIMIT,\n","    processes=True,              # для стабильности\n",")\n","print(client.dashboard_link)     # ссылка на дашборд для мониторинга\n","\n","# ─── Загрузка данных по частям с Dask ─────────────────────────────────────────\n","\n","print(\"Считываем метаданные для разбиения...\")\n","\n","# Берём последнюю часть как валидацию (примерно последние 1–2 месяца)\n","valid_part = 3\n","train_parts = [1, 2]   # можно [1] для теста, потом добавить 2\n","\n","train_files = [f\"{DATA_PATH}train_features_part_{p}.parquet\" for p in train_parts]\n","valid_file  = f\"{DATA_PATH}train_features_part_{valid_part}.parquet\"\n","\n","# Dask DataFrame (lazy чтение)\n","ddf_train = dd.read_parquet(train_files, engine=\"pyarrow\")\n","ddf_valid = dd.read_parquet(valid_file, engine=\"pyarrow\")\n","\n","print(f\"Train parts: {len(train_files)} | Valid: 1\")\n","\n","# ─── Подготовка массивов ──────────────────────────────────────────────────────\n","\n","exclude_cols = [\n","    \"customer_id\", \"event_id\", \"event_dttm\", \"date\",\n","    \"target\",                     # таргет отдельно\n","    # если есть другие служебные — добавь\n","]\n","\n","feature_cols = [c for c in ddf_train.columns if c not in exclude_cols]\n","\n","print(f\"Количество признаков: {len(feature_cols)}\")\n","\n","# Категориальные в Dask\n","for col in cat_features:\n","    if col in feature_cols:\n","        ddf_train[col] = ddf_train[col].astype(\"category\")\n","        ddf_valid[col] = ddf_valid[col].astype(\"category\")\n","\n","# X/y как Dask arrays\n","X_train = ddf_train[feature_cols].to_dask_array(lengths=True)\n","y_train = ddf_train[\"target\"].to_dask_array(lengths=True)\n","\n","X_valid = ddf_valid[feature_cols].to_dask_array(lengths=True)\n","y_valid = ddf_valid[\"target\"].to_dask_array(lengths=True)\n","\n","# ─── Dask-LightGBM ────────────────────────────────────────────────────────────\n","\n","print(\"Запуск обучения Dask-LightGBM...\")\n","\n","model = DaskLGBMClassifier(\n","    objective=\"binary\",\n","    metric=\"average_precision\",          # PR-AUC\n","    learning_rate=LEARNING_RATE,\n","    num_leaves=NUM_LEAVES,\n","    max_depth=MAX_DEPTH,\n","    feature_fraction=FEATURE_FRACTION,\n","    bagging_fraction=BAGGING_FRACTION,\n","    bagging_freq=BAGGING_FREQ,\n","    scale_pos_weight=POS_WEIGHT,\n","    random_state=1842,\n","    client=client,\n","    n_jobs=-1,\n","    verbosity=-1,\n",")\n","\n","model.fit(\n","    X_train,\n","    y_train,\n","    eval_set=[(X_valid, y_valid)],\n","    eval_metric=\"average_precision\",\n","    callbacks=[\n","        lgb.early_stopping(stopping_rounds=EARLY_STOPPING),\n","        lgb.log_evaluation(VERBOSE_EVAL),\n","    ],\n",")\n","\n","# ─── Оценка на валидации ─────────────────────────────────────────────────────\n","\n","print(\"Предсказание на валидации...\")\n","preds_valid = model.predict_proba(X_valid)[:, 1].compute()  # вероятности класса 1\n","\n","y_valid_np = y_valid.compute()\n","pr_auc = average_precision_score(y_valid_np, preds_valid)\n","print(f\"PR-AUC на валидации: {pr_auc:.5f}\")\n","\n","# ─── Сохранение модели ───────────────────────────────────────────────────────\n","\n","model_file = f\"{MODEL_PATH}lgb_dask_baseline_part_{'-'.join(map(str, train_parts))}_PR{pr_auc:.4f}.txt\"\n","model.booster_.save_model(model_file)\n","print(f\"Модель сохранена: {model_file}\")\n","\n","client.close()\n","print(\"Готово!\", datetime.now().strftime(\"%Y-%m-%d %H:%M\"))"]}]}